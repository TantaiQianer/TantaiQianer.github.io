<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="澹台千儿" href="http://tantaiqianer.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="澹台千儿" href="http://tantaiqianer.github.io/atom.xml"><link rel="alternate" type="application/json" title="澹台千儿" href="http://tantaiqianer.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://tantaiqianer.github.io/machine-learning/embodied-AI/MLM-WM-notes/"><title>具身智能基础 - 具身智能 - 机器学习 - 计算机 | Tantai Qianer = 澹台千儿</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?58bf9ed12e0698075dbd6500fec2ae08";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta name="generator" content="Hexo 6.0.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">具身智能基础</h1><div class="meta"><span class="item" title="创建时间：2024-09-10 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-09-10T00:00:00+08:00">2024-09-10</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>2.6k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>2 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Tantai Qianer</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gipey84bjtj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1giclwrdwyaj20zk0m8are.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gicitspjpbj20zk0m81ky.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gipewr8iypj20zk0m8b29.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gicljitigmj20zk0m87fp.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gipexw3o58j20zk0m8e81.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="item" rel="index" title="分类于 计算机"><span itemprop="name">计算机</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/" itemprop="item" rel="index" title="分类于 具身智能"><span itemprop="name">具身智能</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://tantaiqianer.github.io/machine-learning/embodied-AI/MLM-WM-notes/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="澹台千儿"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="澹台千儿"></span><div class="body md" itemprop="articleBody"><p>挑战一周速成具身智能基础知识。—— 失败了。</p><p><span id="more"></span></p><p>这是 2024 年 7 月中山大学和鹏城实验室联合发布的一篇多模态大模型 (MLMs) 及世界模型 (WMs) 时代的具身智能综述的论文总结。</p><p><img data-src="../../../images/machineLearning/embodied-AI/MLM_Survey_0.png" alt width="80%"></p><h1 id="tldr"><a class="anchor" href="#tldr">#</a> TL;DR</h1><p>文章的主要内容和贡献包括：</p><ol><li>分析了具身智能的四个主要研究目标<ul><li>具身感知 (embodied perception)</li><li>具身交互 (embodied interaction)</li><li>具身智能体 (embodied agent)</li><li>虚拟到现实的适应 (sim2real adaptation)</li></ul></li><li>探讨了虚拟世界和真实世界之间 MLM 的复杂性</li><li>总结了具身智能现有的挑战和未来的发展方向</li></ol><h1 id="具身机器人分类"><a class="anchor" href="#具身机器人分类">#</a> 具身机器人分类</h1><p><img data-src="../../../images/machineLearning/embodied-AI/MLM_Survey_1_Robots.png" alt width="600px"></p><h2 id="固定基座机器人"><a class="anchor" href="#固定基座机器人">#</a> 固定基座机器人</h2><p><span class="pink">固定基座机器人</span> (fixed-base robots) 由于其紧凑和高精度操作的特点，已经在实验室自动化、教育培训和工业制造领域得到广泛使用。其另一重要特点是具有高度可编程性。但由于固定底座设计限制了移动的自由，因此固定基座机器人通常与人类或者其它机器人配合工作。</p><h2 id="轮式和履带式机器人"><a class="anchor" href="#轮式和履带式机器人">#</a> 轮式和履带式机器人</h2><p><span class="pink">轮式机器人</span> (wheeled robots) 是一种常见的移动机器人，在配备传感器的情况下可以实现自主导航和环境感知。其优点包括结构简单、成本较低、能源效率高以及可以快速移动。其缺点是在复杂地形和恶劣环境下移动性有限，且负载能力有限。其主要应用于仓储物流和安检领域。</p><p><span class="pink">履带式机器人</span> (tracked robots) 有更强的越野能力和机动性，在农业、救援和军事领域应用广泛，但其能源效率相对轮式机器人较低。</p><h2 id="四足机器人"><a class="anchor" href="#四足机器人">#</a> 四足机器人</h2><p><span class="pink">四足机器人</span> (quadruped robots) 得益于其多关节控制，具有高稳定性和适应性，适用于救援和军事应用。其缺点是设计复杂、制作成本高昂，且能源利用率低下。</p><h2 id="人形机器人"><a class="anchor" href="#人形机器人">#</a> 人形机器人</h2><p><span class="pink">人形机器人</span> (humanoid robots) 一般具有类似人类的外形和灵巧的手部设计，这使得其可以执行复杂的任务。目前，人形机器人在服务业、医疗保健业和人机协作环境中应用不断扩大。</p><h2 id="仿生机器人"><a class="anchor" href="#仿生机器人">#</a> 仿生机器人</h2><p><span class="pink">仿生机器人</span> (biomimetic robots) 通过模仿自然界生物的高效运动方式和能力，实现对复杂和动态环境的适应，其主要包括类鱼机器人 (fish-like robots)、类昆虫机器人 (insect-like robots) 和软体机器人 (soft-bodied robots) 等。目前，仿生机器人设计和制造工艺复杂，成本高昂，大规模生产和应用受到限制。此外，由于对柔性材料的使用，其在极端情况下的耐用性和可靠性有限。</p><h1 id="具身模拟器"><a class="anchor" href="#具身模拟器">#</a> 具身模拟器</h1><p><span class="pink">具身模拟器</span> (embodied simulator) 是在虚拟空间进行具身机器人测试模拟的载体，其通过模拟实现具身机器人的高效、安全测试。但由于模拟空间与现实空间存在差异，因此具身模拟器的目标之一就是缩小虚拟与现实之间的差异。</p><h2 id="通用模拟器"><a class="anchor" href="#通用模拟器">#</a> 通用模拟器</h2><p><span class="pink">通用模拟器</span> (general simulator) 是指可以模拟各种场景和任务的模拟器，如 <span class="pink">MuJoCo</span>、<span class="pink">Bullet</span>、<span class="pink">V-REP</span> 等。</p><h2 id="基于真实场景的模拟器"><a class="anchor" href="#基于真实场景的模拟器">#</a> 基于真实场景的模拟器</h2><h1 id="具身感知"><a class="anchor" href="#具身感知">#</a> 具身感知</h1><p>具身感知的要求不仅仅是识别图像中的物体，还需要在机器人本身移动过程理解场景的三维关系，并基于视觉信息预测和推理，以执行复杂任务。文章认为，具身感知发展的未来方向是以具身智能体为核心的<strong>视觉推理</strong>和<strong>社会智能</strong>。</p><h2 id="主动视觉感知"><a class="anchor" href="#主动视觉感知">#</a> 主动视觉感知</h2><p>就是 SLAM 那些。</p><h2 id="3d-视觉定位"><a class="anchor" href="#3d-视觉定位">#</a> 3D 视觉定位</h2><p>主要任务是基于自然语言描述实现 3D 场景中的定位。</p><h2 id="视觉语言导航"><a class="anchor" href="#视觉语言导航">#</a> 视觉语言导航</h2><p><span class="pink">视觉语言导航</span> (visual language navigation, <strong>VLN</strong>) 即使具身智能体依靠语言指令在不可见的环境中导航。</p><h2 id="无视觉感知触觉"><a class="anchor" href="#无视觉感知触觉">#</a> 无视觉感知：触觉</h2><h1 id="具身交互"><a class="anchor" href="#具身交互">#</a> 具身交互</h1><h2 id="具身问答"><a class="anchor" href="#具身问答">#</a> 具身问答</h2><h2 id="具身抓取"><a class="anchor" href="#具身抓取">#</a> 具身抓取</h2><h1 id="具身智能体"><a class="anchor" href="#具身智能体">#</a> 具身智能体</h1><p>一个<span class="pink">智能体</span> (agent) 被定义为一个具有感知所在环境和采取行动以实现特定目标能力的自主实体。下图是具身智能车的一个时间顺序的具身智能体架构概览。</p><p><img data-src="../../../images/machineLearning/embodied-AI/MLM_Survey_2_Agent.png" alt width="800px"></p><p>基于上图可以看出，具身智能体的主要任务包括：</p><ol><li>（视觉）感知</li><li>高层级任务规划</li><li>低层级动作规划</li></ol><h2 id="具身多模态基础模型"><a class="anchor" href="#具身多模态基础模型">#</a> 具身多模态基础模型</h2><p>为实现上述任务，具身智能体需要一个集成多种模态的模型。Google DeepMind 发现使用大模型和多样的数据集是目前最佳的策略，这对应 RT 系列模型。其中，RT-2 模型引入了<span class="pink">视觉 - 语言 - 动作模型</span> (Vision-Language-Action Model, <strong>VLA</strong>), 同时还使用了<span class="pink">思维链</span> (Chain-of-Thought, <strong>CoT</strong>) 实现多步语义推理。然而，<ins>基于 Transformer 的模型由于需要视觉、语言、具身状态等多模态长上下文输入，因此模型存在低效的问题</ins>。例如，RT-2 模型的推理频率仅为 1-3 Hz. 因此也可以使用 Mamba 等模型进行改进，例如 RoboMamba.</p><h2 id="具身任务规划"><a class="anchor" href="#具身任务规划">#</a> 具身任务规划</h2><h3 id="基于-llm-涌现能力的规划"><a class="anchor" href="#基于-llm-涌现能力的规划">#</a> 基于 LLM 涌现能力的规划</h3><p>任务规划是将复杂任务分解为简单任务（原语）的过程。例如将 “把一个苹果放在盘子上” 分解为 “寻找苹果”、“拿起苹果”、“寻找盘子”、“放下苹果” 等简单任务，这些任务分别对应导航、抓取、导航、抓取等基本任务。由于任务是基于自然语言描述的，因此使用 LLM 的效果显著优于基于规则的方法。基于规则的方法就像之前使用 Chomsky 范式研究自然语言一样，机械且效果有限。</p><h3 id="视觉信息嵌入具身感知模型"><a class="anchor" href="#视觉信息嵌入具身感知模型">#</a> 视觉信息嵌入具身感知模型</h3><p>只使用语言进行任务描述无法使模型应对真实的复杂环境，因此需要视觉信息等多模态输入。一种朴素的做法是使用<strong>对象标签</strong> (object labels)，即通过目标检测为视觉输入的对象添加标签，以方便 LLM 更好进行任务规划。但对于一些复杂动态环境，模型仍然不能有效应对。例如希望模型在浴室中寻找毛巾，当毛巾被放在柜子中时，由于物体标签无法标注柜子中的毛巾，模型不会找到毛巾，而是一直在浴室中寻找。</p><h3 id="基于视觉语言模型"><a class="anchor" href="#基于视觉语言模型">#</a> 基于视觉语言模型</h3><p>基于上述问题，模型实际上需要更强的视觉和语言先验。因此基于<strong>视觉语言模型</strong> (Vision-Language Models, <strong>VLM</strong>) 是一种很好的解决方案。</p><h2 id="具身动作规划"><a class="anchor" href="#具身动作规划">#</a> 具身动作规划</h2><p>在 RoboGPT 的实验中，尽管任务规划的准确率达到了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>96</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">96\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.80556em;vertical-align:-.05556em"></span><span class="mord">9</span><span class="mord">6</span><span class="mord">%</span></span></span></span>, 但实际的任务完成率仅有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>60</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">60\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.80556em;vertical-align:-.05556em"></span><span class="mord">6</span><span class="mord">0</span><span class="mord">%</span></span></span></span>. 这是由于低层动作规划性能所限。因此，有效的动作规划是使具身智能体完成现实任务的关键。</p><h1 id="虚拟到现实的适应"><a class="anchor" href="#虚拟到现实的适应">#</a> 虚拟到现实的适应</h1><h2 id="具身世界模型"><a class="anchor" href="#具身世界模型">#</a> 具身世界模型</h2><h2 id="数据收集和训练"><a class="anchor" href="#数据收集和训练">#</a> 数据收集和训练</h2><h2 id="具身控制"><a class="anchor" href="#具身控制">#</a> 具身控制</h2><h2 id="单模型泛化-all-robots-in-one"><a class="anchor" href="#单模型泛化-all-robots-in-one">#</a> 单模型泛化 (All Robots in One)</h2><h1 id="挑战与未来"><a class="anchor" href="#挑战与未来">#</a> 挑战与未来</h1><h1 id="ref"><a class="anchor" href="#ref">#</a> Ref</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzI0MDcuMDY4ODY=">Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI</span>: 这是 2024 年 7 月中山大学和鹏城实验室联合发布的一篇多模态大模型 (MLMs) 及世界模型 (WMs) 时代的具身智能综述。</li></ul></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-10-08 14:00:44" itemprop="dateModified" datetime="2024-10-08T14:00:44+08:00">2024-10-08</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>澹台千儿 <i class="ic i-at"><em>@</em></i>澹台千儿</li><li class="link"><strong>本文链接：</strong> <a href="http://tantaiqianer.github.io/machine-learning/embodied-AI/MLM-WM-notes/" title="具身智能基础">http://tantaiqianer.github.io/machine-learning/embodied-AI/MLM-WM-notes/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/machine-learning/embodied-AI/foundation-models/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tantaiqianer.github.io&#x2F;images&#x2F;Shoka&#x2F;6833939bly1gipeun65urj20zk0m81ii.jpg" title="综述总结：机器人学中的基础模型"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 具身智能</span><h3>综述总结：机器人学中的基础模型</h3></a></div><div class="item right"><a href="/machine-learning/advanced-ML-notes/1-Intro/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tantaiqianer.github.io&#x2F;images&#x2F;Shoka&#x2F;9ca8d4e098a5e62fe53df1752e08454d3461568723422067.jpg" title="高级机器学习(1)：概论"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 机器学习</span><h3>高级机器学习(1)：概论</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#tldr"><span class="toc-number">1.</span> <span class="toc-text">TL;DR</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">具身机器人分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BA%E5%AE%9A%E5%9F%BA%E5%BA%A7%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.1.</span> <span class="toc-text">固定基座机器人</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AE%E5%BC%8F%E5%92%8C%E5%B1%A5%E5%B8%A6%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.2.</span> <span class="toc-text">轮式和履带式机器人</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E8%B6%B3%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.3.</span> <span class="toc-text">四足机器人</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E5%BD%A2%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.4.</span> <span class="toc-text">人形机器人</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BF%E7%94%9F%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.5.</span> <span class="toc-text">仿生机器人</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%A8%A1%E6%8B%9F%E5%99%A8"><span class="toc-number">3.</span> <span class="toc-text">具身模拟器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E6%A8%A1%E6%8B%9F%E5%99%A8"><span class="toc-number">3.1.</span> <span class="toc-text">通用模拟器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%9C%9F%E5%AE%9E%E5%9C%BA%E6%99%AF%E7%9A%84%E6%A8%A1%E6%8B%9F%E5%99%A8"><span class="toc-number">3.2.</span> <span class="toc-text">基于真实场景的模拟器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%84%9F%E7%9F%A5"><span class="toc-number">4.</span> <span class="toc-text">具身感知</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E5%8A%A8%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5"><span class="toc-number">4.1.</span> <span class="toc-text">主动视觉感知</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3d-%E8%A7%86%E8%A7%89%E5%AE%9A%E4%BD%8D"><span class="toc-number">4.2.</span> <span class="toc-text">3D 视觉定位</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E5%AF%BC%E8%88%AA"><span class="toc-number">4.3.</span> <span class="toc-text">视觉语言导航</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%E8%A7%A6%E8%A7%89"><span class="toc-number">4.4.</span> <span class="toc-text">无视觉感知：触觉</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E4%BA%A4%E4%BA%92"><span class="toc-number">5.</span> <span class="toc-text">具身交互</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E9%97%AE%E7%AD%94"><span class="toc-number">5.1.</span> <span class="toc-text">具身问答</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%8A%93%E5%8F%96"><span class="toc-number">5.2.</span> <span class="toc-text">具身抓取</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E4%BD%93"><span class="toc-number">6.</span> <span class="toc-text">具身智能体</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.1.</span> <span class="toc-text">具身多模态基础模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E4%BB%BB%E5%8A%A1%E8%A7%84%E5%88%92"><span class="toc-number">6.2.</span> <span class="toc-text">具身任务规划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-llm-%E6%B6%8C%E7%8E%B0%E8%83%BD%E5%8A%9B%E7%9A%84%E8%A7%84%E5%88%92"><span class="toc-number">6.2.1.</span> <span class="toc-text">基于 LLM 涌现能力的规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E4%BF%A1%E6%81%AF%E5%B5%8C%E5%85%A5%E5%85%B7%E8%BA%AB%E6%84%9F%E7%9F%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.2.</span> <span class="toc-text">视觉信息嵌入具身感知模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.3.</span> <span class="toc-text">基于视觉语言模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E5%8A%A8%E4%BD%9C%E8%A7%84%E5%88%92"><span class="toc-number">6.3.</span> <span class="toc-text">具身动作规划</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%88%B0%E7%8E%B0%E5%AE%9E%E7%9A%84%E9%80%82%E5%BA%94"><span class="toc-number">7.</span> <span class="toc-text">虚拟到现实的适应</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.1.</span> <span class="toc-text">具身世界模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%92%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">7.2.</span> <span class="toc-text">数据收集和训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E8%BA%AB%E6%8E%A7%E5%88%B6"><span class="toc-number">7.3.</span> <span class="toc-text">具身控制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%95%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96-all-robots-in-one"><span class="toc-number">7.4.</span> <span class="toc-text">单模型泛化 (All Robots in One)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5"><span class="toc-number">8.</span> <span class="toc-text">挑战与未来</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ref"><span class="toc-number">9.</span> <span class="toc-text">Ref</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/machine-learning/embodied-AI/MLM-WM-notes/" rel="bookmark" title="具身智能基础">具身智能基础</a></li><li><a href="/machine-learning/embodied-AI/foundation-models/" rel="bookmark" title="综述总结：机器人学中的基础模型">综述总结：机器人学中的基础模型</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="澹台千儿" data-src="/images/avatar.jpg"><p class="name" itemprop="name">澹台千儿</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">349</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">99</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9saXUtbGlhbmctMzItOTQ=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;liu-liang-32-94"><i class="ic i-zhihu"></i></span> <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL1RhbnRhaVFpYW5lcg==" title="https:&#x2F;&#x2F;github.com&#x2F;TantaiQianer"><i class="ic i-github"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/machine-learning/embodied-AI/foundation-models/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/machine-learning/advanced-ML-notes/1-Intro/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%8F%AF%E8%A7%86%E5%8C%96/" title="分类于 可视化">可视化</a></div><span><a href="/visualization/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="可视化期末复习">可视化期末复习</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BD%91%E7%BB%9C/" title="分类于 网络">网络</a></div><span><a href="/computer-networks/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B02%EF%BC%9A%E7%89%A9%E7%90%86%E5%B1%82/" title="计算机网络(2)：物理层">计算机网络(2)：物理层</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/%E5%87%A0%E4%BD%95%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 几何深度学习">几何深度学习</a></div><span><a href="/machine-learning/geo-deep-learning/1-Intro/" title="几何深度学习(1)：引言">几何深度学习(1)：引言</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%B7%A5%E7%A8%8B%E9%97%AE%E9%A2%98/" title="分类于 工程问题">工程问题</a></div><span><a href="/%E5%B7%A5%E7%A8%8B%E9%97%AE%E9%A2%98/wandb/" title="wandb 使用手册">wandb 使用手册</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/NCO/" title="分类于 NCO">NCO</a></div><span><a href="/machine-learning/NCO/NCO-summary/" title="Neural Combinatorial Optimization 简单总结">Neural Combinatorial Optimization 简单总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="分类于 算法与数据结构">算法与数据结构</a></div><span><a href="/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/basic-alg/%E5%89%8D%E7%BC%80%E5%92%8C/" title="前缀和">前缀和</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" title="分类于 实验报告">实验报告</a></div><span><a href="/machine-learning/exp-notes/exp1-linear-reg/" title="机器学习实验报告(1)：线性回归">机器学习实验报告(1)：线性回归</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="分类于 神经网络与机器学习">神经网络与机器学习</a></div><span><a href="/machine-learning/NN-DL/3-CNN/" title="神经网络与深度学习(3)：卷积神经网络">神经网络与深度学习(3)：卷积神经网络</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E9%87%91%E8%9E%8D%E6%95%B0%E5%AD%A6/" title="分类于 金融数学">金融数学</a> <i class="ic i-angle-right"></i> <a href="/categories/%E9%87%91%E8%9E%8D%E6%95%B0%E5%AD%A6/%E8%B4%A7%E5%B8%81%E9%93%B6%E8%A1%8C%E5%AD%A6/" title="分类于 货币银行学">货币银行学</a></div><span><a href="/fin-math/%E8%B4%A7%E5%B8%81%E9%93%B6%E8%A1%8C%E5%AD%A6%E7%AC%94%E8%AE%B0/%E8%B4%A7%E5%B8%81%E9%93%B6%E8%A1%8C%E5%AD%A6%E7%AC%94%E8%AE%B01%EF%BC%9A%E8%B4%A7%E5%B8%81/" title="货币银行学笔记(1)：货币">货币银行学笔记(1)：货币</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AF%AD%E6%96%87/" title="分类于 语文">语文</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AF%AD%E6%96%87/%E8%AF%AD%E6%B3%95/" title="分类于 语法">语法</a></div><span><a href="/Chinese/Grammar/%E8%AF%8D%E8%AF%AD%E5%92%8C%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86/" title="词语和句子成分">词语和句子成分</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">澹台千儿 @ Tantai Qianer</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">780k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">11:49</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"machine-learning/embodied-AI/MLM-WM-notes/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>