<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="澹台千儿" href="http://tantaiqianer.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="澹台千儿" href="http://tantaiqianer.github.io/atom.xml"><link rel="alternate" type="application/json" title="澹台千儿" href="http://tantaiqianer.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://tantaiqianer.github.io/machine-learning/awesome-papers/ICML2024/"><title>ICML2024-Awesome Papers - awesome papers - 机器学习 - 计算机 | Tantai Qianer = 澹台千儿</title><meta name="generator" content="Hexo 6.0.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">ICML2024-Awesome Papers</h1><div class="meta"><span class="item" title="创建时间：2024-08-12 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-08-12T00:00:00+08:00">2024-08-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>8.5k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>8 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Tantai Qianer</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gicmnywqgpj20zk0m8dwx.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1giclwuom7cj20zk0m8dvn.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gicm0n457cj20zk0m8e81.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gipesrnqv3j20zk0m8ava.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gipet8c1a2j20zk0m8kct.jpg"></li><li class="item" data-background-image="https://tantaiqianer.github.io/images/Shoka/6833939bly1gicitf0kl1j20zk0m87fe.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="item" rel="index" title="分类于 计算机"><span itemprop="name">计算机</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/awesome-papers/" itemprop="item" rel="index" title="分类于 awesome papers"><span itemprop="name">awesome papers</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://tantaiqianer.github.io/machine-learning/awesome-papers/ICML2024/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="澹台千儿"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="澹台千儿"></span><div class="body md" itemprop="articleBody"><p>之前一直想过要阅读各个重要会议的有趣论文，但是一直没有想过具体要怎么做。现在想来还是要先列个单子出来。</p><p><span id="more"></span></p><p>具体打算的话，还是打算先以 Oral 论文为主。这样，这个总的 list 主要就用来列举论文有哪些，然后是每篇论文的题目、领域、摘要和作者等补充信息。摘要会把中文也扔上去。</p><p>所以这就是个体力活嘛。先干好再慢慢来。那就开始吧！</p><h1 id="test-of-time-award"><a class="anchor" href="#test-of-time-award">#</a> Test of Time Award</h1><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC90ZXN0LW9mLXRpbWUvMzgwMDQ=">DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</span>, <em>Jeffrey Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell</em>.</p><details class="info"><summary>摘要</summary><div><blockquote><p>Abstract: We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re- purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient la- beled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We in- vestigate and visualize the semantic clustering of deep convolutional features with respect to a va- riety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed fea- ture, and report novel results that significantly outperform the state-of-the-art on several impor- tant vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimenta- tion with deep representations across a range of visual concept learning paradigms.</p><p>摘要翻译：我们评估了在大量固定的物体识别任务上以完全监督的方式训练的深度卷积网络的激活中提取的特征是否可以重新用于新的通用任务。我们的通用任务可能与最初训练的任务有很大不同，并且可能没有足够的标记或未标记数据来传统地训练或调整深度架构以适应新任务。我们研究并可视化了深度卷积特征在各种此类任务中的语义聚类，包括场景识别、领域自适应和细粒度识别挑战。我们比较了依赖不同网络级别来定义固定特征的有效性，并报告了在几个重要的视觉挑战中明显优于最先进技术的新结果。我们正在发布 DeCAF，这是这些深度卷积激活特征的开源实现，以及所有相关的网络参数，以使视觉研究人员能够在一系列视觉概念学习范式中使用深度表示进行实验。</p></blockquote></div></details><p>贾扬清等人的作品，是 Caffe 的前身。</p><h1 id="best-paper"><a class="anchor" href="#best-paper">#</a> Best Paper</h1><ol><li><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9wb3N0ZXIvMzMzNjA=">Debating with More Persuasive LLMs Leads to More Truthful Answers</span>, <em>Akbir Khan, John Hughes, Dan Valentine, Laura Ruis, Kshitij Sachan, Ansh Radhakrishnan, Edward Grefenstette, Samuel Bowman, Tim Rocktäschel, Ethan Perez</em>. (Poster)</p><details class="info"><summary>摘要</summary><div><blockquote><p>Abstract: Common methods for aligning large language models (LLMs) with desired behaviour heavily rely on human-labelled data. However, as models grow increasingly sophisticated, they will surpass human expertise, and the role of human evaluation will evolve into non-experts overseeing experts. In anticipation of this, we ask: can weaker models assess the correctness of stronger models? We investigate this question in an analogous setting, where stronger models (experts) possess the necessary information to answer questions and weaker models (non-experts) lack this information. The method we evaluate is debate, where two LLM experts each argue for a different answer, and a non-expert selects the answer. We find that debate consistently helps both non-expert models and humans answer questions, achieving 76% and 88% accuracy respectively (naive baselines obtain 48% and 60%). Furthermore, optimising expert debaters for persuasiveness in an unsupervised manner improves non-expert ability to identify the truth in debates. Our results provide encouraging empirical evidence for the viability of aligning models with debate in the absence of ground truth.</p><p>将大型语言模型 (LLM) 与期望行为对齐的常用方法严重依赖于人工标记的数据。然而，随着模型变得越来越复杂，它们将超越人类的专业知识，而人类评估的角色将演变为非专家监督专家。为了预见到这一点，我们问：较弱的模型能否评估较强模型的正确性？我们在类似的环境中调查了这个问题，其中较强的模型（专家）拥有回答问题的必要信息，而较弱的模型（非专家）缺乏这些信息。我们评估的方法是辩论，其中两个 LLM 专家各自争论不同的答案，然后由非专家选择答案。我们发现辩论始终有助于非专家模型和人类回答问题，分别达到 76% 和 88% 的准确率（原始的基线获得 48% 和 60%）。此外，以无监督的方式优化专家辩论者的说服力可以提高非专家在辩论中识别真相的能力。我们的结果为在缺乏基本事实的情况下将模型与辩论相结合的可行性提供了令人鼓舞的实证证据。</p></blockquote></div></details></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9wb3N0ZXIvMzM0NTA=">Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo</span>, <em>Stephen Zhao, Rob Brekelmans, Alireza Makhzani, Roger Grosse</em>. (Oral)</p><details class="info"><summary>摘要</summary><div><blockquote><p>Abstract: Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward or potential function over the full sequence. In this work, we leverage the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic inference problems. In particular, we use learned twist functions to estimate the expected future value of the potential at each timestep, which enables us to focus inference-time computation on promising partial sequences. We propose a novel contrastive method for learning the twist functions, and establish connections with the rich literature of soft reinforcement learning. As a complementary application of our twisted SMC framework, we present methods for evaluating the accuracy of language model inference techniques using novel bidirectional SMC bounds on the log partition function. These bounds can be used to estimate the KL divergence between the inference and target distributions in both directions. We apply our inference evaluation techniques to show that twisted SMC is effective for sampling undesirable outputs from a pretrained model (a useful component of harmlessness training and automated red-teaming), generating reviews with varied sentiment, and performing infilling tasks.</p><p>摘要翻译：大型语言模型 (LLM) 的众多功能和安全技术，包括 RLHF、自动红队、快速工程和填充，都可以视为从给定奖励或潜在函数在整个序列上定义的非正则化目标分布中进行采样。在这项工作中，我们利用丰富的顺序蒙特卡罗 (SMC) 工具包来解决这些概率推理问题。具体来说，我们使用学习到的扭曲函数来估计每个时间步的预期未来潜力值，这使我们能够将推理时间计算集中在有希望的部分序列上。我们提出了一种学习扭曲函数的新型对比方法，并与丰富的软强化学习文献建立了联系。作为我们扭曲的 SMC 框架的补充应用，我们提出了使用对数分区函数的新型双向 SMC 界限来评估语言模型推理技术准确性的方法。这些界限可用于估计推理和目标分布在两个方向上的 KL 散度。我们应用推理评估技术来证明扭曲的 SMC 可以有效地从预训练模型（无害训练和自动红队的有用组成部分）中采样不良输出，生成具有不同情绪的评论，并执行填充任务。</p></blockquote></div></details></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzI0MDMuMDY2MzQ=">Stealing part of a production language model</span>, <em>Nicholas Carlini, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, Matthew Jagielski, Milad Nasr, Arthur Conmy, Itay Yona, Eric Wallace, David Rolnick, Florian Tramèr</em>. (Oral)</p><details class="info"><summary>摘要</summary><div><blockquote><p>Abstract: We introduce the first model-stealing attack that extracts precise, nontrivial information from black-box production language models like OpenAI's ChatGPT or Google's PaLM-2. Specifically, our attack recovers the embedding projection layer (up to symmetries) of a transformer model, given typical API access. For under $20 USD, our attack extracts the entire projection matrix of OpenAI's Ada and Babbage language models. We thereby confirm, for the first time, that these black-box models have a hidden dimension of 1024 and 2048, respectively. We also recover the exact hidden dimension size of the gpt-3.5-turbo model, and estimate it would cost under $2,000 in queries to recover the entire projection matrix. We conclude with potential defenses and mitigations, and discuss the implications of possible future work that could extend our attack.</p><p>摘要翻译：我们介绍了第一个模型窃取攻击，该攻击从黑盒生产语言模型（如 OpenAI 的 ChatGPT 或 Google 的 PaLM-2）中提取精确、非平凡的信息。具体来说，在给定典型 API 访问的情况下，我们的攻击会恢复 Transformer 模型的嵌入投影层（最多对称）。不到 20 美元，我们的攻击就可以提取 OpenAI 的 Ada 和 Babbage 语言模型的整个投影矩阵。因此，我们首次确认这些黑盒模型的隐藏维度分别为 1024 和 2048。我们还恢复了 gpt-3.5-turbo 模型的精确隐藏维度大小，并估计恢复整个投影矩阵的查询成本不到 2,000 美元。我们总结了潜在的防御和缓解措施，并讨论了可能扩展我们攻击的未来工作的影响。</p></blockquote></div></details></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9wb3N0ZXIvMzQ1MzU=">Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</span>, <em>Patrick Esser · Sumith Kulal · Andreas Blattmann · Rahim Entezari · Jonas Müller · Harry Saini · Yam Levi · Dominik Lorenz · Axel Sauer · Frederic Boesel · Dustin Podell · Tim Dockhorn · Zion English · Robin Rombach</em>. (Poster)</p><details class="info"><summary>摘要</summary><div><blockquote><p>Abstract: Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models. Stability AI is considering making experimental data, code, and model weights publicly available.</p><p>摘要翻译：扩散模型通过将数据的前向路径反转为噪声来从噪声中创建数据，并已成为图像和视频等高维感知数据的一种强大的生成建模技术。整流是一种最近的生成模型公式，它将数据和噪声以直线连接起来。尽管它具有更好的理论特性和概念简单性，但它尚未被确定为标准做法。在这项工作中，我们改进了现有的噪声采样技术，通过将它们偏向感知相关的尺度来训练整流模型。通过一项大规模研究，我们证明了这种方法与现有的高分辨率文本到图像合成扩散公式相比具有更优越的性能。此外，我们提出了一种用于文本到图像生成的新型基于变压器的架构，它对两种模态使用单独的权重，并实现图像和文本标记之间的双向信息流，从而改善了文本理解、排版和人类偏好评级。我们证明这种架构遵循可预测的扩展趋势，并将较低的验证损失与改进的文本到图像合成相关联，这是通过各种指标和人工评估来衡量的。我们最大的模型比最先进的模型表现更好。Stability AI 正在考虑公开实验数据、代码和模型权重。</p></blockquote></div></details></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9wb3N0ZXIvMzQ2NDk=">Information Complexity of Stochastic Convex Optimization: Applications to Generalization, Memorization, and Tracing</span>, <em>Idan Attias · Gintare Karolina Dziugaite · Mahdi Haghifam · Roi Livni · Daniel Roy</em>. (Poster)</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9wb3N0ZXIvMzQ2ODY=">Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution</span>, <em>Aaron Lou · Chenlin Meng · Stefano Ermon</em>. (Poster)</p></li><li></li></ol><h1 id="oral"><a class="anchor" href="#oral">#</a> Oral</h1><h1 id="others-to-be-continued"><a class="anchor" href="#others-to-be-continued">#</a> Others (To Be Continued)</h1><h1 id="ref"><a class="anchor" href="#ref">#</a> Ref</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9hd2FyZHNfZGV0YWls">ICML2024 Awards 列表</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjL3ZpcnR1YWwvMjAyNC9ldmVudHMvb3JhbA==">ICML2024 Oral 论文列表</span></li></ul></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-08-13 10:47:02" itemprop="dateModified" datetime="2024-08-13T10:47:02+08:00">2024-08-13</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="澹台千儿 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.jpg" alt="澹台千儿 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="澹台千儿 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>澹台千儿 <i class="ic i-at"><em>@</em></i>澹台千儿</li><li class="link"><strong>本文链接：</strong> <a href="http://tantaiqianer.github.io/machine-learning/awesome-papers/ICML2024/" title="ICML2024-Awesome Papers">http://tantaiqianer.github.io/machine-learning/awesome-papers/ICML2024/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/mathematics/differential-geometry.md/1-differential-manifold/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tantaiqianer.github.io&#x2F;images&#x2F;Shoka&#x2F;6833939bly1giclil3m4ej20zk0m8tn8.jpg" title="微分几何笔记(1)：微分流形"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 微分几何</span><h3>微分几何笔记(1)：微分流形</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#test-of-time-award"><span class="toc-number">1.</span> <span class="toc-text">Test of Time Award</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#best-paper"><span class="toc-number">2.</span> <span class="toc-text">Best Paper</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#oral"><span class="toc-number">3.</span> <span class="toc-text">Oral</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#others-to-be-continued"><span class="toc-number">4.</span> <span class="toc-text">Others (To Be Continued)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ref"><span class="toc-number">5.</span> <span class="toc-text">Ref</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/machine-learning/awesome-papers/ICML2024/" rel="bookmark" title="ICML2024-Awesome Papers">ICML2024-Awesome Papers</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="澹台千儿" data-src="/images/avatar.jpg"><p class="name" itemprop="name">澹台千儿</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">302</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">88</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL1RhbnRhaVFpYW5lcg==" title="https:&#x2F;&#x2F;github.com&#x2F;TantaiQianer"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9saXUtbGlhbmctMzItOTQ=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;liu-liang-32-94"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPXlvdXJpZA==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;yourid"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;about.me&#x2F;yourname"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B7%A5%E7%A8%8B%E9%97%AE%E9%A2%98/" title="分类于 工程问题">工程问题</a></div><span><a href="/%E5%B7%A5%E7%A8%8B%E9%97%AE%E9%A2%98/zotero/" title="Zotero">Zotero</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%83%B3%E6%B3%95/" title="分类于 想法">想法</a></div><span><a href="/ideas-and-diary/240324%E5%9B%BD%E5%8D%9A/" title="国博">国博</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" title="分类于 实验报告">实验报告</a></div><span><a href="/machine-learning/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A4-%E7%89%9B%E9%A1%BF%E6%B3%95/" title="机器学习实验报告(4)：牛顿法求解对数概率回归">机器学习实验报告(4)：牛顿法求解对数概率回归</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="分类于 算法与数据结构">算法与数据结构</a></div><span><a href="/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/string-alg/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95/" title="字符串匹配算法">字符串匹配算法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%95%B0%E5%AD%A6/" title="分类于 数学">数学</a> <i class="ic i-angle-right"></i> <a href="/categories/%E6%95%B0%E5%AD%A6/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/" title="分类于 数学分析">数学分析</a></div><span><a href="/mathematics/analysis/3%20%E7%BA%A7%E6%95%B0/" title="级数">级数</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/TODO/" title="分类于 TODO">TODO</a></div><span><a href="/TODO/" title="My TODO List">My TODO List</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/machine-learning/GNN/" title="分类于 GNN">GNN</a></div><span><a href="/machine-learning/GNN/Over-Smoothing%20%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/" title="Over-Smoothing 论文总结">Over-Smoothing 论文总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%9B%BE%E5%BD%A2%E5%AD%A6/" title="分类于 图形学">图形学</a></div><span><a href="/computer-graphics/%E5%9B%BE%E5%BD%A2%E5%AD%A6-%E7%9B%AE%E5%BD%95&%E6%A6%82%E8%BF%B0/" title="图形学-目录&amp;概述">图形学-目录&概述</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" title="分类于 操作系统">操作系统</a></div><span><a href="/OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/" title="操作系统概念总结">操作系统概念总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="分类于 计算机">计算机</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/" title="分类于 语言">语言</a> <i class="ic i-angle-right"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AF%AD%E8%A8%80/Python/" title="分类于 Python">Python</a></div><span><a href="/programming/Python/Jupyter%20Notebook%E5%85%A5%E9%97%A8/" title="Jupyter Notebook入门知识">Jupyter Notebook入门知识</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">澹台千儿 @ Tantai Qianer</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">696k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">10:33</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"machine-learning/awesome-papers/ICML2024/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>